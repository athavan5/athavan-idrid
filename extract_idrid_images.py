# -*- coding: utf-8 -*-
"""IDRiD_SMALL_PATCH_December_3_UNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lst17QG1FQHwu4vxXOrQ3oNqSVzxdQyC
"""


import zipfile
import shutil
from pathlib import Path
from sklearn.model_selection import train_test_split
import random
from PIL import Image
import numpy as np
from collections import defaultdict
import torch
import os
import cv2
import re

import glob
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms.functional as TF
import matplotlib.pyplot as plt

#from __future__ import annotations
import math
from dataclasses import dataclass
from typing import Tuple, Dict, Any

import torch.nn as nn
import torch.nn.functional as F

from torch.cuda.amp import autocast, GradScaler
import math
import time
from sklearn.metrics import average_precision_score
from torch.serialization import add_safe_globals

'''
#Open the Zipfile
with zipfile.ZipFile('A. Segmentation.zip', 'r') as zip_ref:
    # List all contents
    file_list = zip_ref.namelist()
    print("Contents of the ZIP file:")
    for file in file_list:
        print(file)
'''

#Extract the files
with zipfile.ZipFile('A. Segmentation.zip', 'r') as zip_ref:
    zip_ref.extractall('')

"""Combining Images from Train/Test Sets to Do Stratification"""

def combine_image_folders(source_folder1, source_folder2, destination_folder):
    """
    Combines images from two source folders into a single destination folder.

    Args:
        source_folder1 (str): Path to the first source folder.
        source_folder2 (str): Path to the second source folder.
        destination_folder (str): Path to the folder where all images will be combined.
    """

    # Create the destination folder if it doesn't exist
    if not os.path.exists(destination_folder):
        os.makedirs(destination_folder)
        print(f"Created destination folder: {destination_folder}")

    # Function to copy/move images from a source folder
    def process_folder(source_path):
        for filename in os.listdir(source_path):
            # Construct full paths for source and destination files
            source_file_path = os.path.join(source_path, filename)
            destination_file_path = os.path.join(destination_folder, filename)

            # Check if it's a file and an image (you can add more image extensions)
            if os.path.isfile(source_file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tif', '.tiff')):
                try:
                    # Copy the file (use shutil.move instead of shutil.copy2 if you want to move the files)
                    shutil.copy2(source_file_path, destination_file_path)
                    print(f"Copied '{filename}' to '{destination_folder}'")
                except shutil.SameFileError:
                    print(f"Skipped '{filename}': File already exists in destination.")
                except Exception as e:
                    print(f"Error copying '{filename}': {e}")

    # Process images from the first source folder
    print(f"\nProcessing images from '{source_folder1}'...")
    process_folder(source_folder1)

    # Process images from the second source folder
    print(f"\nProcessing images from '{source_folder2}'...")
    process_folder(source_folder2)

    print("\nImage combination complete.")

# Example usage:

def combine_original_images():
    og_image_train = "A. Segmentation/1. Original Images/a. Training Set"
    og_image_test = "A. Segmentation/1. Original Images/b. Testing Set"
    combined_images_folder = "A. Segmentation/1. Original Images/c. All Images"
    combine_image_folders(og_image_train, og_image_test, combined_images_folder)
    print("\nImage combination complete.")

gt_ma_train = "A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/1. Microaneurysms"
gt_ma_test = "A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/1. Microaneurysms"

gt_he_train = "A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/2. Haemorrhages"
gt_he_test = "A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/2. Haemorrhages"

gt_se_train = "A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/4. Soft Exudates"
gt_se_test = "A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/4. Soft Exudates"

gt_ex_train = "A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/3. Hard Exudates"
gt_ex_test = "A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/3. Hard Exudates"

gt_od_train = "A. Segmentation/2. All Segmentation Groundtruths/a. Training Set/5. Optic Disc"
gt_od_test = "A. Segmentation/2. All Segmentation Groundtruths/b. Testing Set/5. Optic Disc"

combined_ma = "A. Segmentation/2. All Segmentation Groundtruths/Combined MA/"
combined_he = "A. Segmentation/2. All Segmentation Groundtruths/Combined HE/"
combined_se = "A. Segmentation/2. All Segmentation Groundtruths/Combined SE/"
combined_ex = "A. Segmentation/2. All Segmentation Groundtruths/Combined EX/"
combined_od = "A. Segmentation/2. All Segmentation Groundtruths/Combined OD/"

combine_image_folders(gt_ma_train, gt_ma_test, combined_ma)
combine_image_folders(gt_he_train, gt_he_test, combined_he)

combine_image_folders(gt_se_train, gt_se_test, combined_se)

combine_image_folders(gt_ex_train, gt_ex_test, combined_ex)

combine_image_folders(gt_od_train, gt_od_test, combined_od)

"""Spltting Images into Balanced Sets with Wasserstein-Driven Evolutionary Stratification (WDES)"""


try:
    import imageio.v3 as iio  # robust for png/jpg/tif
except Exception:
    import imageio as iio

# 1) Configure your directories
IMG_DIR  = Path("A. Segmentation/1. Original Images/c. All Images")
MASK_ROOT = Path("A. Segmentation/2. All Segmentation Groundtruths")

LESION_FOLDERS = {
    "Microaneurysms": MASK_ROOT / "Combined MA",
    "Haemorrhages":   MASK_ROOT / "Combined HE",
    "Soft Exudates":  MASK_ROOT / "Combined SE",
    "Hard Exudates":  MASK_ROOT / "Combined EX",
    "Optic Disc":  MASK_ROOT / "Combined OD",
}
LESION_ORDER = ["Microaneurysms", "Haemorrhages", "Soft Exudates", "Hard Exudates", "Optic Disc"]  # C = 5

# Split parameters
K = 3  # train/val/test
TARGET_SPLIT = [0.7, 0.15, 0.15]  # train, val, test (must sum to 1.0)
FOLD_NAMES = ["train", "val", "test"]

# Evolutionary optimizer params
SEED = 42
POP_SIZE = 24
N_GEN = 150
MUTATION_RATE = 0.25       # per-individual, per-generation
SWAP_RATE = 0.30           # probability to swap chunks between two individuals
TOURNAMENT = 3
SIZE_TOL_FRAC = 0.10       # ±10% tolerance on target split sizes before penalty ramps up

# Output
OUT_CSV = "wdes_split.csv"
MATERIALIZE_DIRS = True
OUT_ROOT = Path("A. Segmentation/3. WDES_Splits")  # where we symlink train/val/test

import cv2
# 2) Utility: robust image/mask reader
def read_gray(path):
    try:
        arr = iio.imread(str(path))
    except Exception:
        # fallback for LZW-compressed TIFFs
        arr = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
        if arr is None:
            raise
    if arr.ndim == 3 and arr.shape[-1] in (3, 4):
        arr = np.dot(arr[..., :3], [0.2989, 0.5870, 0.1140])
    return arr.astype(np.float32)

def binarize_mask(arr):
    # treat >0 as lesion pixel; normalize any labels >1
    return (arr > 0).astype(np.float32)

_SUFFIX_STRIP_RE = re.compile(
    r'(?i)(?:[-_ ]?(?:MA|HE|SE|EX|OD|Microaneurysms?|Haemorrhages?|Soft[-_ ]?Exudates?|Hard[-_ ]?Exudates?|Optic[-_ ]?Disc?))$'
)

def normalize_stem(name: str) -> str:
    """Remove common lesion suffix tokens from filename stems, case-insensitive."""
    s = name
    s = _SUFFIX_STRIP_RE.sub('', s)     # strip one trailing lesion token if present
    s = s.rstrip('-_ ')                 # clean leftover separators
    return s

def index_by_stem(folder, exts=(".png",".jpg",".jpeg",".tif",".tiff",".bmp")):
    mapping = {}
    for ext in exts:
        for p in folder.glob(f"*{ext}"):
            mapping[normalize_stem(p.stem)] = p
    return mapping

def collect_dataset():
    img_map = index_by_stem(IMG_DIR)
    mask_maps = {lesion: index_by_stem(path) for lesion, path in LESION_FOLDERS.items()}

    samples = []  # list of dicts: {stem, img_path, mask_paths{lesion:Path|None}}
    for stem, ipath in img_map.items():
        mpaths = {}
        for lesion in LESION_ORDER:
            mpaths[lesion] = mask_maps[lesion].get(stem, None)
        samples.append({"stem": stem, "img_path": ipath, "mask_paths": mpaths})
    samples.sort(key=lambda d: d["stem"])
    return samples

def report_missing_masks(samples):
    missing = {lesion: [] for lesion in LESION_ORDER}
    for s in samples:
        for lesion in LESION_ORDER:
            if s["mask_paths"][lesion] is None:
                missing[lesion].append(s["stem"])
    for lesion in LESION_ORDER:
        n = len(missing[lesion])
        if n:
            print(f"[WARN] {n} images missing {lesion} mask. Example(s): {missing[lesion][:5]}")
        else:
            print(f"[OK] All images have {lesion} mask.")

# In main(), right after collect_dataset():
samples = collect_dataset()
print(f"Found {len(samples)} images.")
report_missing_masks(samples)

# 4) Compute per-sample lesion proportions (label vector)
def compute_label_vectors(samples):
    feats = []
    for s in samples:
        # Get image size to normalize pixel counts
        img = read_gray(s["img_path"])
        H, W = img.shape
        denom = float(H*W)

        vec = []
        for lesion in LESION_ORDER:
            mp = s["mask_paths"][lesion]
            if mp is None:
                vec.append(0.0)
            else:
                m = binarize_mask(read_gray(mp))
                vec.append(float(m.sum())/denom)
        feats.append(np.array(vec, dtype=np.float64))
    feats = np.stack(feats, axis=0)  # [N, C]
    return feats

# 5) Objective: WDES loss + mild size balance term
def compute_fold_stats(assign, feats, K):
    """
    assign: [N] ints in [0..K-1]
    feats:  [N,C] per-sample lesion proportions
    Returns: global F (C,), per-fold Fk (K,C), fold_sizes (K,)
    """
    N, C = feats.shape
    F_global = feats.mean(axis=0)  # global fraction estimate
    Fk = np.zeros((K, C), dtype=np.float64)
    sizes = np.zeros(K, dtype=np.int64)

    for k in range(K):
        idx = (assign == k)
        if idx.any():
            Fk[k] = feats[idx].mean(axis=0)
            sizes[k] = idx.sum()
        else:
            # empty fold: leave zeros; objective will penalize
            Fk[k] = 0.0
            sizes[k] = 0
    return F_global, Fk, sizes

def wdes_loss(assign, feats, K, target_split):
    """
    L_WD = (1/K) * sum_k sum_c |F_c - F_c^k|
    plus penalties for size imbalance and empty folds.
    """
    N = feats.shape[0]
    F_global, Fk, sizes = compute_fold_stats(assign, feats, K)

    # Core WDES objective
    wd = np.abs(Fk - F_global[None, :]).sum(axis=1).mean()

    # Size penalty
    target_sizes = np.array([round(t * N) for t in target_split], dtype=np.float64)
    tol = SIZE_TOL_FRAC * target_sizes.clip(min=1)
    size_dev = np.abs(sizes - target_sizes)
    # Zero penalty inside tolerance, linear outside
    size_pen = np.maximum(0.0, size_dev - tol).sum() / N

    # Empty fold penalty
    empty_pen = (sizes == 0).sum() * 10.0

    return wd + 0.5 * size_pen + empty_pen

# 6) Initialization: greedy seeding (rare-class-first heuristic)
def greedy_init(feats, K, target_split):
    N, C = feats.shape
    target_sizes = np.array([round(t * N) for t in target_split], dtype=int)
    assign = -np.ones(N, dtype=int)

    # rarity score = sum of lesion proportions (lower = rarer)
    rarity = feats.sum(axis=1)
    order = np.argsort(rarity)  # rare first

    fold_loads = np.zeros(K, dtype=int)

    for i in order:
        # try placing into fold that best improves objective wrt current partial
        best_k, best_score = None, float('inf')
        for k in range(K):
            if fold_loads[k] >= target_sizes[k] and fold_loads.min() < target_sizes.min():
                # lightly prioritize undersized folds
                continue
            assign[i] = k
            score = wdes_loss(assign.copy(), feats, K, target_split)
            if score < best_score:
                best_k, best_score = k, score
        if best_k is None:
            best_k = np.argmin(fold_loads)  # fallback
        assign[i] = best_k
        fold_loads[best_k] += 1

    return assign

# 7) Evolutionary optimizer (mutation + swap + selection)
def evolve_wdes(feats, K, target_split, seed=SEED):
    rng = random.Random(seed)
    np.random.seed(seed)

    N = feats.shape[0]
    target_sizes = np.array([round(t*N) for t in target_split], dtype=int)

    # Create initial population
    pop = []
    # 1 greedy + (POP_SIZE-1) random respecting rough sizes
    base = greedy_init(feats, K, target_split)
    pop.append(base)
    for _ in range(POP_SIZE-1):
        # random assign then "repair" toward targets
        idx = np.arange(N)
        np.random.shuffle(idx)
        assign = -np.ones(N, dtype=int)
        start = 0
        for k in range(K):
            take = target_sizes[k] if k < K-1 else (N - start)
            assign[idx[start:start+take]] = k
            start += take
        # small random swaps
        for __ in range(max(1, N//20)):
            i, j = np.random.randint(0, N), np.random.randint(0, N)
            assign[i], assign[j] = assign[j], assign[i]
        pop.append(assign)

    def fitness(a):
        return wdes_loss(a, feats, K, target_split)

    # Evaluate
    scores = [fitness(a) for a in pop]

    for gen in range(N_GEN):
        new_pop = []
        # Elitism: keep best 2
        elite_idx = np.argsort(scores)[:2]
        new_pop.extend([pop[elite_idx[0]].copy(), pop[elite_idx[1]].copy()])

        # Generate rest
        while len(new_pop) < POP_SIZE:
            # Tournament select two parents
            cand = rng.sample(range(POP_SIZE), k=min(TOURNAMENT, POP_SIZE))
            p1 = min(cand, key=lambda i: scores[i])
            cand = rng.sample(range(POP_SIZE), k=min(TOURNAMENT, POP_SIZE))
            p2 = min(cand, key=lambda i: scores[i])

            child1 = pop[p1].copy()
            child2 = pop[p2].copy()

            # Swap chunks with some probability
            if rng.random() < SWAP_RATE:
                # swap a random slice
                a, b = sorted([rng.randrange(N), rng.randrange(N)])
                child1[a:b], child2[a:b] = child2[a:b].copy(), child1[a:b].copy()

            # Mutations: reassign a few indices
            for child in (child1, child2):
                if rng.random() < MUTATION_RATE:
                    mcount = max(1, N // 50)
                    for _ in range(mcount):
                        i = rng.randrange(N)
                        newk = rng.randrange(K)
                        child[i] = newk

            # Local repair toward target sizes (simple pass)
            for child in (child1, child2):
                sizes = np.bincount(child, minlength=K)
                # reduce oversized folds
                for k in range(K):
                    while sizes[k] > target_sizes[k]:
                        idx_k = np.where(child == k)[0]
                        i = rng.choice(idx_k.tolist())
                        # move to most undersized fold
                        unders = np.argsort(sizes - target_sizes)
                        for uk in unders:
                            if sizes[uk] < target_sizes[uk]:
                                child[i] = uk
                                sizes[k] -= 1
                                sizes[uk] += 1
                                break

            new_pop.extend([child1, child2])

        # Trim to POP_SIZE
        pop = new_pop[:POP_SIZE]
        scores = [fitness(a) for a in pop]

    best_idx = int(np.argmin(scores))
    return pop[best_idx], float(scores[best_idx])

# 8) Materialize results: CSV + optional symlinked folders
def write_csv(samples, assign, csv_path=OUT_CSV):
    import csv
    with open(csv_path, "w", newline="") as f:
        w = csv.writer(f)
        header = ["stem", "split", "image_path"] + [f"mask_{l.replace(' ', '_').lower()}" for l in LESION_ORDER]
        w.writerow(header)
        for s, k in zip(samples, assign):
            row = [s["stem"], FOLD_NAMES[k], str(s["img_path"])]
            for lesion in LESION_ORDER:
                mp = s["mask_paths"][lesion]
                row.append("" if mp is None else str(mp))
            w.writerow(row)
    print(f"Wrote: {csv_path}")

def safe_symlink(src, dst):
    dst.parent.mkdir(parents=True, exist_ok=True)
    if dst.exists() or dst.is_symlink():
        dst.unlink()
    try:
        # Try symbolic link (works on Linux/macOS, or Windows with dev mode/admin)
        os.symlink(src, dst)
    except (OSError, NotImplementedError):
        # Fallback: just copy the file instead
        shutil.copy2(src, dst)

def materialize_splits(samples, assign, out_root=OUT_ROOT):
    # Folder structure:
    # out_root/{train,val,test}/images/, out_root/{...}/masks/{Lesion}/
    for split in FOLD_NAMES:
        (out_root / split / "images").mkdir(parents=True, exist_ok=True)
        for lesion in LESION_ORDER:
            (out_root / split / "masks" / lesion).mkdir(parents=True, exist_ok=True)

    # Create symlinks
    for s, k in zip(samples, assign):
        split = FOLD_NAMES[k]
        # image
        src_img = s["img_path"]
        dst_img = OUT_ROOT / split / "images" / f"{s['stem']}{src_img.suffix}"
        safe_symlink(src_img, dst_img)

        # masks
        for lesion in LESION_ORDER:
            mp = s["mask_paths"][lesion]
            if mp is not None:
                dst_mask = OUT_ROOT / split / "masks" / lesion / f"{s['stem']}{mp.suffix}"
                safe_symlink(mp, dst_mask)

    print(f"Materialized symlinked splits under: {out_root}")

def main():
    random.seed(SEED); np.random.seed(SEED)
    print("Collecting dataset…")
    samples = collect_dataset()
    if len(samples) == 0:
        raise RuntimeError(f"No images found in {IMG_DIR}. Check the path or extensions.")
    print(f"Found {len(samples)} images.")

    print("Computing label vectors (per-image lesion proportions)…")
    feats = compute_label_vectors(samples)  # [N,4]
    print("Label vectors computed.")

    print("Running WDES evolutionary split…")
    best_assign, best_score = evolve_wdes(feats, K, TARGET_SPLIT, seed=SEED)
    print(f"Best WDES score: {best_score:.6f}")

    # Report quick fold stats
    F_global, Fk, sizes = compute_fold_stats(best_assign, feats, K)
    print("\nGlobal lesion fractions (order:", LESION_ORDER, ")")
    print(F_global.round(6))
    print("Per-fold lesion fractions:")
    for k in range(K):
        print(FOLD_NAMES[k], "size=", sizes[k], "fractions=", Fk[k].round(6))

    # Save CSV + materialize
    write_csv(samples, best_assign, OUT_CSV)
    if MATERIALIZE_DIRS:
        materialize_splits(samples, best_assign, OUT_ROOT)


"""Apply Augmentations"""

class RetinaSegDataset(Dataset):
    """
    Loads one RGB image and its 4 lesion masks as a 4-channel tensor (C=4,H,W).
    If augment=True: applies the SAME random crop/affine/flip to image AND masks.
    """
    def __init__(
        self,
        img_dir: str,
        mask_root: str,
        lesion_subdirs = ("Combined MA", "Combined HE", "Combined SE", "Combined EX", "Combined OD"),
        image_size: int | tuple = 256,
        augment: bool = True,
        degrees: float = 30,
        translate=(0.10, 0.10),
        scale_range=(0.9, 1.1),
        shear_range=(-15, 15),
        rr_crop_scale=(0.9, 1.0),
        rr_crop_ratio=(0.75, 1.333),
        normalize_mean=(0.485, 0.456, 0.406),
        normalize_std=(0.229, 0.224, 0.225),
        crop_left_frac: float = 0.055,
        crop_right_frac: float = 0.013,
        per_image_crop: dict | None = None,

        # JUST ADDED -> patch-based training options
        patch_mode: bool = False,
        patches_per_image: int = 1,
    ):
        self.img_dir = Path(img_dir)
        self.mask_root = Path(mask_root)
        self.lesion_subdirs = lesion_subdirs
        self.image_size = (image_size, image_size) if isinstance(image_size, int) else tuple(image_size)
        self.augment = augment
        self.crop_left_frac = crop_left_frac
        self.crop_right_frac = crop_right_frac
        self.per_image_crop = per_image_crop or {}

        # JUST ADDED -> patch-based options
        self.patch_mode = patch_mode          # if True: thus, random 512×512 patches
        self.patches_per_image = max(1, patches_per_image)

        # augmentation params
        self.degrees = degrees
        self.translate = translate
        self.scale_range = scale_range
        self.shear_range = shear_range
        self.rr_crop_scale = rr_crop_scale
        self.rr_crop_ratio = rr_crop_ratio

        # collect images (any common image extension)
        self.img_paths = sorted(
            sum([list(self.img_dir.glob(f"*.{ext}")) for ext in ["jpg","jpeg","png","tif","tiff","bmp"]], [])
        )
        if len(self.img_paths) == 0:
            raise FileNotFoundError(f"No images found in {self.img_dir}")

        # verify all lesion folders exist
        for sub in self.lesion_subdirs:
            if not (self.mask_root / sub).exists():
                raise FileNotFoundError(f"Missing mask subfolder: {self.mask_root / sub}")

        self.normalize = transforms.Normalize(mean=normalize_mean, std=normalize_std)

    def __len__(self):
        # In patch mode, we conceptually replicate each image P times per epoch.
        if self.patch_mode and self.patches_per_image > 1:
            return len(self.img_paths) * self.patches_per_image
        return len(self.img_paths)

    def _find_mask_path(self, subdir: Path, stem: str):
        # try multiple extensions for masks
        for ext in ("tif","tiff","png","jpg","jpeg","bmp"):
            p = subdir / f"{stem}.{ext}"
            if p.exists():
                return p
        # fallback: glob by stem.*
        hits = glob.glob(str(subdir / f"{stem}.*"))
        if len(hits) > 0:
            return Path(hits[0])
        # CHANGE: return None instead of raising
        return None

    def _load_image(self, p: Path):
        # PIL can read TIFF; for LZW you may need imagecodecs (you already installed earlier)
        return Image.open(p).convert("RGB")

    def _load_mask_as_binary_L(self, p: Path):
        # convert to single-channel and binarize (>0 -> 1)
        m = Image.open(p).convert("L")
        # ensure binary (some masks are 0/255 or multi-gray); threshold at >0
        m = m.point(lambda x: 255 if x > 0 else 0)
        return m

    def __getitem__(self, idx):
        # In patch_mode, many dataset indices map to the same image,
        # but we draw a fresh random patch each time.
        if self.patch_mode:
            img_idx = idx % len(self.img_paths)
        else:
            img_idx = idx

        img_path = self.img_paths[img_idx]
        stem = img_path.stem

        # load image
        img = self._load_image(img_path)

        # load 4 lesion masks in a fixed order
        mask_imgs = []
        present = []
        for sub in self.lesion_subdirs:
            mp = self._find_mask_path(self.mask_root / sub, stem)
            if mp is None:
                # mark missing; make a blank mask same size as the image
                present.append(0.0)
                w, h = img.size
                m = Image.new("L", (w, h), 0)
                mask_imgs.append(m)
            else:
                present.append(1.0)
                mask_imgs.append(self._load_mask_as_binary_L(mp))

        # PER-IMAGE CROP SETUP
        left_frac = self.crop_left_frac
        right_frac = self.crop_right_frac

        # If this image has a custom crop, override the defaults
        if stem in self.per_image_crop:
            lf, rf = self.per_image_crop[stem]
            left_frac = lf
            right_frac = rf

        # Additional crop on left/right sides of images to remove black borders
        if (left_frac is not None) and (right_frac is not None) and (left_frac  >= 0.0 or right_frac >= 0.0):
            w, h = img.size
            left_margin = int(left_frac * w)
            right_margin = int(right_frac * w)    # e.g. 5% of width on each side

            # make sure we don't crop away everything
            if left_margin + right_margin < w:
                left   = left_margin
                right  = w - right_margin
                top    = 0
                bottom = h

                img = img.crop((left, top, right, bottom))
                mask_imgs = [m.crop((left, top, right, bottom)) for m in mask_imgs]

        # === AUGMENTATION ===
        if self.augment:
            # ----- TRAINING -----
            if self.patch_mode:
                # Patch-based: random 512×512 crop at *native* resolution
                th, tw = self.image_size  # (H, W)
                W, H = img.size           # PIL: (W, H)

                if H < th or W < tw:
                    # Fallback: if image is somehow smaller, resize up once
                    img = TF.resize(img, self.image_size, interpolation=TF.InterpolationMode.BILINEAR)
                    mask_imgs = [
                        TF.resize(m, self.image_size, interpolation=TF.InterpolationMode.NEAREST)
                        for m in mask_imgs
                    ]
                else:
                    # Randomly choose a 512×512 window (overlaps happen across calls)
                    i, j, h_c, w_c = transforms.RandomCrop.get_params(
                        img, output_size=self.image_size
                    )
                    img = TF.crop(img, i, j, th, tw)
                    mask_imgs = [TF.crop(m, i, j, th, tw) for m in mask_imgs]
            else:
                # Old behaviour: random resized crop over (90–100%) of image, then resize to 512×512
                i, j, h, w = transforms.RandomResizedCrop.get_params(
                    img, scale=self.rr_crop_scale, ratio=self.rr_crop_ratio
                )
                img = TF.resized_crop(
                    img, i, j, h, w, self.image_size,
                    interpolation=TF.InterpolationMode.BILINEAR
                )
                mask_imgs = [
                    TF.resized_crop(
                        m, i, j, h, w, self.image_size,
                        interpolation=TF.InterpolationMode.NEAREST
                    )
                    for m in mask_imgs
                ]

            # Random affine (shared) — same for both modes
            angle = random.uniform(-self.degrees, self.degrees)
            tx = int(self.translate[0] * self.image_size[1])
            ty = int(self.translate[1] * self.image_size[0])
            translate = (random.randint(-tx, tx), random.randint(-ty, ty))
            scale = random.uniform(self.scale_range[0], self.scale_range[1])
            shear = random.uniform(self.shear_range[0], self.shear_range[1])

            img = TF.affine(
                img, angle=angle, translate=translate, scale=scale, shear=shear,
                interpolation=TF.InterpolationMode.BILINEAR, fill=0
            )
            mask_imgs = [
                TF.affine(
                    m, angle=angle, translate=translate, scale=scale, shear=shear,
                    interpolation=TF.InterpolationMode.NEAREST, fill=0
                )
                for m in mask_imgs
            ]

            # Random horizontal flip (shared)
            if random.random() < 0.5:
                img = TF.hflip(img)
                mask_imgs = [TF.hflip(m) for m in mask_imgs]

        else:
            # Validation/Test
            # Keep original behaviour: resize the *whole* FOV to 512×512
            img = TF.resize(img, self.image_size, interpolation=TF.InterpolationMode.BILINEAR)
            mask_imgs = [
                TF.resize(m, self.image_size, interpolation=TF.InterpolationMode.NEAREST)
                for m in mask_imgs
            ]

        # === To tensor ===
        img_t = TF.to_tensor(img)                          # (3,H,W), float32 in [0,1]
        mask_t_list = [TF.pil_to_tensor(m).float() / 255.0 # each -> (1,H,W) in {0,1}
                       for m in mask_imgs]
        masks_t = torch.cat(mask_t_list, dim=0)            # (4,H,W)

        #NEW LINE ADDED
        # Recompute presence AFTER all transforms
        # present_t[c] = 1 if that lesion has any positive pixel in this augmented patch
        present_t = (masks_t.view(masks_t.shape[0], -1).max(dim=1).values > 0).float()

        # Normalize image only
        img_t = self.normalize(img_t)

        # NEW: presence vector as a tensor (4,)
        #present_t = torch.tensor(present, dtype=torch.float32)

        # CHANGE: return presence_t too
        return img_t, masks_t, present_t, stem



#MODEL RUN
def run_training():
    per_image_crop = {
    "IDRiD_04": (0.015, 0.085),
    "IDRiD_12": (0.015, 0.085),
    "IDRiD_57": (0.015, 0.085),
    "IDRiD_65": (0.015, 0.085),
    }

    # Your directories
    img_train_folder  = "A. Segmentation/3. WDES_Splits/train/images"
    mask_train_root   = "A. Segmentation/3. WDES_Splits/train/masks"   # contains 4 subfolders

    img_val_folder    = "A. Segmentation/3. WDES_Splits/val/images"
    mask_val_root     = "A. Segmentation/3. WDES_Splits/val/masks"

    img_test_folder   = "A. Segmentation/3. WDES_Splits/test/images"
    mask_test_root    = "A. Segmentation/3. WDES_Splits/test/masks"

    lesion_subdirs = ("Haemorrhages", "Hard Exudates", "Microaneurysms", "Soft Exudates", "Optic Disc")

    train_ds = RetinaSegDataset(
        img_train_folder, mask_train_root, lesion_subdirs=lesion_subdirs,
        image_size=512, augment=True, crop_left_frac=0.055, crop_right_frac=0.13,
        per_image_crop=per_image_crop, patch_mode=True, patches_per_image=8)

    val_ds   = RetinaSegDataset(
        img_val_folder, mask_val_root, lesion_subdirs=lesion_subdirs,
        image_size=512, augment=False, crop_left_frac=0.055, crop_right_frac=0.13,
        per_image_crop=per_image_crop)

    test_ds  = RetinaSegDataset(
        img_test_folder, mask_test_root, lesion_subdirs=lesion_subdirs,
        image_size=512, augment=False, crop_left_frac=0.055, crop_right_frac=0.13,
        per_image_crop=per_image_crop)

    train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=4, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=4, pin_memory=True)
    test_loader  = DataLoader(test_ds,  batch_size=8, shuffle=False, num_workers=4, pin_memory=True)

    #checking the lengths of these datasets
    print(len(train_ds))
    print(len(val_ds))
    print(len(test_ds))

if __name__ == "__main__":
    combine_original_images()
    main()
    run_training()

'''
"""Testing"""

# --- Safe loader wrapper for PyTorch 2.6 ---
def load_ckpt_forgiving(path, device):
    try:
        # Try the strict safe load first
        add_safe_globals([np.core.multiarray.scalar])
        return torch.load(path, map_location=device, weights_only=True)
    except Exception:
        # Fallback to old behavior if file was saved before PyTorch 2.6
        return torch.load(path, map_location=device, weights_only=False)

@torch.no_grad()
def evaluate_one_lesion_on_test(
    model_class,
    lesion_idx,
    ckpt_path,
    test_loader,
    device="cuda",
    lesion_names=("Haemorrhages","Hard Exudates","Microaneurysms","Soft Exudates", "Optic Disc"),
    prob_threshold=0.5,
):
    model = model_class(in_ch=3, base=64, lesion_names=lesion_names).to(device)
    ckpt = load_ckpt_forgiving(ckpt_path, device)
    model.load_state_dict(ckpt["model"])
    model.eval()

    lname = lesion_names[lesion_idx]
    print(f"\nEvaluating {lname}...")

    dice_sum = iou_sum = n_samples = 0
    probs_all, targs_all = [], []

    for imgs, masks, present, names in test_loader:
        imgs   = imgs.to(device, non_blocking=True)
        target = masks[:, lesion_idx:lesion_idx+1].to(device)
        pres   = present[:, lesion_idx].to(device)
        logits = model(imgs, lesion_idx)
        probs  = torch.sigmoid(logits)
        preds  = (probs >= prob_threshold).float()
        pres_mask = pres.view(-1,1,1,1)

        inter = (preds * target * pres_mask).sum(dim=(2,3))
        pred_sum = (preds * pres_mask).sum(dim=(2,3))
        targ_sum = (target * pres_mask).sum(dim=(2,3))
        union = (pred_sum + targ_sum - inter).clamp_min(1e-6)
        dice = (2 * inter / (pred_sum + targ_sum + 1e-6)).squeeze(1)
        iou  = (inter / union).squeeze(1)

        dice_sum += dice[pres>0].sum().item()
        iou_sum  += iou[pres>0].sum().item()
        n_samples += int((pres>0).sum().item())

        if (pres>0).any():
            probs_all.append(probs[pres>0].cpu().numpy().ravel())
            targs_all.append(target[pres>0].cpu().numpy().ravel())

    mean_dice = dice_sum / max(1, n_samples)
    mean_iou  = iou_sum / max(1, n_samples)
    if len(probs_all) > 0:
        probs_flat = np.concatenate(probs_all)
        targs_flat = np.concatenate(targs_all)
        aupr = average_precision_score(targs_flat, probs_flat)
    else:
        aupr = float("nan")

    print(f"[{lname}] Dice={mean_dice:.4f} | IoU={mean_iou:.4f} | AUPR={aupr:.4f}")
    return {"dice": mean_dice, "iou": mean_iou, "aupr": aupr}

lesion_names = ("Haemorrhages","Hard Exudates","Microaneurysms","Soft Exudates", "Optic Disc")
device = "cuda" if torch.cuda.is_available() else "cpu"

results = {}
for i, lname in enumerate(lesion_names):
    ckpt = f"checkpoints_unet_shared/unet_shared_{lname}_best.pth"
    results[lname] = evaluate_one_lesion_on_test(
        model_class=UNetShared,
        lesion_idx=i,
        ckpt_path=ckpt,
        test_loader=test_loader,
        device=device,
        lesion_names=lesion_names,
    )

print("\n=== Test Results Summary ===")
for lname, m in results.items():
    print(f"{lname:18s} | Dice {m['dice']:.4f} | IoU {m['iou']:.4f} | AUPR {m['aupr']:.4f}")

IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD  = (0.229, 0.224, 0.225)

def denormalize(img_t, mean=IMAGENET_MEAN, std=IMAGENET_STD):
    """
    img_t: (3,H,W) tensor after Normalize
    returns: (H,W,3) numpy image in [0,1]
    """
    if isinstance(mean, tuple):
        mean = torch.tensor(mean)
    if isinstance(std, tuple):
        std = torch.tensor(std)

    mean = mean.view(3, 1, 1)
    std  = std.view(3, 1, 1)
    img = img_t * std + mean
    img = img.clamp(0, 1)
    return img.permute(1, 2, 0).cpu().numpy()

"""Visualize Predicted Segmentation Map"""

from torch.serialization import add_safe_globals

# (you already defined this above; include here if needed)
def load_ckpt_forgiving(path, device):
    try:
        add_safe_globals([np.core.multiarray.scalar])
        return torch.load(path, map_location=device, weights_only=True)
    except Exception:
        return torch.load(path, map_location=device, weights_only=False)


@torch.no_grad()
def visualize_single_lesion_prediction(
    model_class,
    ckpt_path: str,
    lesion_names,
    lesion_idx: int,
    dataset,
    sample_idx: int,
    device: str = "cuda",
    prob_threshold: float = 0.5,
):
    """
    Show prediction for ONE lesion on ONE image.

    lesion_idx: index into lesion_names and mask channels (0..len-1)
    dataset: e.g. test_ds or val_ds
    sample_idx: which image in that dataset to visualize
    """
    # 1) Build and load model for this lesion-set
    model = model_class(in_ch=3, base=64, lesion_names=lesion_names).to(device)
    ckpt = load_ckpt_forgiving(ckpt_path, device)
    model.load_state_dict(ckpt["model"])
    model.eval()

    lname = lesion_names[lesion_idx]
    print(f"Visualizing lesion: {lname} (index {lesion_idx})")
    print(f"Checkpoint: {ckpt_path}")
    print(f"Sample index: {sample_idx}")

    # 2) Get one sample from dataset
    img_t, masks_t, present_t, stem = dataset[sample_idx]   # img_t: (3,H,W), masks_t: (C,H,W)
    print(f"Image stem: {stem}")

    # Move to device for inference
    img_in = img_t.unsqueeze(0).to(device)  # (1,3,H,W)

    # 3) Forward pass for THIS lesion only
    logits = model(img_in, lesion_idx)      # (1,1,H,W)
    prob_map = torch.sigmoid(logits)[0, 0].cpu().numpy()  # (H,W)
    pred_mask = (prob_map >= prob_threshold).astype(np.float32)

    # 4) Ground-truth mask for this lesion
    gt_mask = masks_t[lesion_idx].cpu().numpy()  # (H,W)

    # 5) Denormalize image for display
    img_vis = denormalize(img_t.cpu())

    # 6) Plot
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    axes[0].imshow(img_vis)
    axes[0].set_title(f"Original image\n{stem}")
    axes[0].axis("off")

    axes[1].imshow(img_vis)
    axes[1].imshow(gt_mask, alpha=0.5)
    axes[1].set_title(f"GT mask: {lname}")
    axes[1].axis("off")

    axes[2].imshow(img_vis)
    axes[2].imshow(pred_mask, alpha=0.5)
    axes[2].set_title(f"Predicted mask ({lname})\nthreshold = {prob_threshold}")
    axes[2].axis("off")

    plt.tight_layout()
    plt.show()

# Map lesion name -> index
lesion_to_idx = {name: i for i, name in enumerate(lesion_names)}

lesion_name = "Optic Disc"
lesion_idx = lesion_to_idx[lesion_name]

ckpt_path = f"checkpoints_unet_shared/unet_shared_{lesion_name}_best.pth"
sample_idx = 11  # 0-based index into test_ds

visualize_single_lesion_prediction(
    model_class=UNetShared,
    ckpt_path=ckpt_path,
    lesion_names=lesion_names,
    lesion_idx=lesion_idx,
    dataset=test_ds,
    sample_idx=sample_idx,
    device=device,
    prob_threshold=0.5,
)

'''